# Arona Backend Configuration
# Copy this file to .env.backend and customize for your deployment

# ============================================================================
# LLM Configuration (Required)
# ============================================================================
LLM_PROVIDER=openai                    # openai, azure, anthropic, custom, local
LLM_MODEL_NAME=gpt-4o-mini             # Model identifier
LLM_API_KEY=your-api-key-here          # API key for the provider
LLM_BASE_URL=https://api.openai.com/v1 # Optional: Custom base URL
LLM_TEMPERATURE=0.7                    # Optional: Sampling temperature
LLM_MAX_TOKENS=4096                    # Optional: Max tokens in response

# ============================================================================
# Embedding Configuration (Required)
# ============================================================================
EMBEDDING_PROVIDER=openai              # openai, azure, custom, local
EMBEDDING_MODEL_NAME=text-embedding-3-large
EMBEDDING_API_KEY=your-api-key-here
EMBEDDING_BASE_URL=https://api.openai.com/v1
EMBEDDING_EMBEDDING_DIM=3072           # Required: Embedding dimension

# ============================================================================
# Vision Model Configuration (Optional)
# ============================================================================
VISION_PROVIDER=openai                 # openai, azure, custom, local
VISION_MODEL_NAME=gpt-4o               # Vision-capable model
VISION_API_KEY=your-api-key-here
VISION_BASE_URL=https://api.openai.com/v1

# ============================================================================
# Reranker Configuration (Optional)
# ============================================================================
RERANKER_ENABLED=true                  # Enable/disable reranking
RERANKER_PROVIDER=local                # local or api
RERANKER_MODEL_PATH=~/.huggingface/models/bge-reranker-v2-gemma
RERANKER_USE_FP16=false                # Use FP16 for local reranker
RERANKER_BATCH_SIZE=16                 # Batch size for reranking

# ============================================================================
# Storage Configuration
# ============================================================================
WORKING_DIR=./rag_storage              # RAG storage directory
UPLOAD_DIR=./uploads                   # Upload directory for documents

# ============================================================================
# RAGAnything Configuration
# ============================================================================
PARSER=mineru                          # Parser: mineru or docling
ENABLE_IMAGE_PROCESSING=true           # Process images in documents
ENABLE_TABLE_PROCESSING=true           # Process tables in documents
ENABLE_EQUATION_PROCESSING=true        # Process equations in documents

# ============================================================================
# API Server Configuration
# ============================================================================
API_HOST=0.0.0.0                       # Host to bind to
API_PORT=8000                          # Port to bind to
CORS_ORIGINS=*                         # CORS allowed origins (comma-separated)

# ============================================================================
# Example Configurations
# ============================================================================

# --- OpenAI Configuration ---
# LLM_PROVIDER=openai
# LLM_MODEL_NAME=gpt-4o-mini
# LLM_API_KEY=sk-...
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL_NAME=text-embedding-3-large
# EMBEDDING_API_KEY=sk-...
# EMBEDDING_EMBEDDING_DIM=3072

# --- Azure OpenAI Configuration ---
# LLM_PROVIDER=azure
# LLM_MODEL_NAME=gpt-4o-mini
# LLM_API_KEY=your-azure-key
# LLM_BASE_URL=https://your-resource.openai.azure.com/
# EMBEDDING_PROVIDER=azure
# EMBEDDING_MODEL_NAME=text-embedding-3-large
# EMBEDDING_API_KEY=your-azure-key
# EMBEDDING_BASE_URL=https://your-resource.openai.azure.com/
# EMBEDDING_EMBEDDING_DIM=3072

# --- LM Studio (Local) Configuration ---
# LLM_PROVIDER=local
# LLM_MODEL_NAME=local-model
# LLM_API_KEY=not-needed
# LLM_BASE_URL=http://localhost:1234/v1
# EMBEDDING_PROVIDER=local
# EMBEDDING_MODEL_NAME=nomic-embed-text
# EMBEDDING_API_KEY=not-needed
# EMBEDDING_BASE_URL=http://localhost:1234/v1
# EMBEDDING_EMBEDDING_DIM=768
# RERANKER_ENABLED=false

# --- Custom API (vLLM, TGI, etc.) Configuration ---
# LLM_PROVIDER=custom
# LLM_MODEL_NAME=Qwen/Qwen2.5-72B-Instruct
# LLM_API_KEY=your-custom-key
# LLM_BASE_URL=https://your-vllm-endpoint.com/v1
# EMBEDDING_PROVIDER=custom
# EMBEDDING_MODEL_NAME=BAAI/bge-large-en-v1.5
# EMBEDDING_API_KEY=your-custom-key
# EMBEDDING_BASE_URL=https://your-embedding-endpoint.com/v1
# EMBEDDING_EMBEDDING_DIM=1024


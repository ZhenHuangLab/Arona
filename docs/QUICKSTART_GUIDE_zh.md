# RAG-Anything æ–°æ‰‹å¿«é€Ÿå…¥é—¨æŒ‡å—

> **ç¿»è¯‘è¯´æ˜**: è¿™æ˜¯ä¸ºä¸­æ–‡ç”¨æˆ·å‡†å¤‡çš„å¿«é€Ÿå…¥é—¨æŒ‡å—ã€‚The user requested this in Chinese: "How should I use this RAG-Anything project? Can you summarize the current situation and create a tutorial for newcomers?"

## ğŸ“– ç›®å½•

1. [RAG-Anything æ˜¯ä»€ä¹ˆï¼Ÿ](#1-rag-anything-æ˜¯ä»€ä¹ˆ)
2. [æ ¸å¿ƒåŠŸèƒ½](#2-æ ¸å¿ƒåŠŸèƒ½)
3. [ç³»ç»Ÿæ¶æ„](#3-ç³»ç»Ÿæ¶æ„)
4. [å¿«é€Ÿå¼€å§‹](#4-å¿«é€Ÿå¼€å§‹)
5. [ä½¿ç”¨åœºæ™¯å’Œç¤ºä¾‹](#5-ä½¿ç”¨åœºæ™¯å’Œç¤ºä¾‹)
6. [HPC é›†ç¾¤éƒ¨ç½²](#6-hpc-é›†ç¾¤éƒ¨ç½²slurm)
7. [é…ç½®è¯¦è§£](#7-é…ç½®è¯¦è§£)
8. [å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)
9. [è¿›é˜¶ä½¿ç”¨](#9-è¿›é˜¶ä½¿ç”¨)

---

## 1. RAG-Anything æ˜¯ä»€ä¹ˆï¼Ÿ

**RAG-Anything** æ˜¯ä¸€ä¸ª**å…¨èƒ½å¤šæ¨¡æ€æ–‡æ¡£å¤„ç† RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿ**ï¼Œå»ºç«‹åœ¨ [LightRAG](https://github.com/HKUDS/LightRAG) ä¹‹ä¸Šã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ RAG-Anythingï¼Ÿ

ä¼ ç»Ÿçš„ RAG ç³»ç»Ÿåªèƒ½å¤„ç†çº¯æ–‡æœ¬ï¼Œä½†ç°ä»£æ–‡æ¡£å¾€å¾€åŒ…å«ï¼š
- ğŸ“Š **è¡¨æ ¼æ•°æ®**
- ğŸ–¼ï¸ **å›¾ç‰‡ã€å›¾è¡¨**  
- ğŸ“ **æ•°å­¦å…¬å¼**
- ğŸ“„ **æ··åˆæ’ç‰ˆçš„ PDFã€Office æ–‡æ¡£**

RAG-Anything è§£å†³äº†è¿™ä¸ªç—›ç‚¹ï¼Œ**ä¸€ç«™å¼å¤„ç†æ‰€æœ‰ç±»å‹çš„æ–‡æ¡£å†…å®¹**ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

| ç‰¹æ€§ | è¯´æ˜ |
|-----|------|
| ğŸ”„ ç«¯åˆ°ç«¯å¤šæ¨¡æ€æµç¨‹ | ä»æ–‡æ¡£è§£æåˆ°æ™ºèƒ½é—®ç­”ä¸€æ¡é¾™ |
| ğŸ“„ é€šç”¨æ–‡æ¡£æ”¯æŒ | PDFã€Wordã€PPTã€Excelã€å›¾ç‰‡ã€Markdown ç­‰ |
| ğŸ§  ä¸“ä¸šå†…å®¹åˆ†æ | é’ˆå¯¹å›¾ç‰‡ã€è¡¨æ ¼ã€å…¬å¼çš„ä¸“é—¨å¤„ç†å™¨ |
| ğŸ”— å¤šæ¨¡æ€çŸ¥è¯†å›¾è°± | è‡ªåŠ¨æå–å®ä½“å’Œè·¨æ¨¡æ€å…³ç³» |
| âš¡ çµæ´»çš„å¤„ç†æ¨¡å¼ | æ”¯æŒ MinerUã€Docling ç­‰å¤šç§è§£æå™¨ |
| ğŸ¯ æ··åˆæ™ºèƒ½æ£€ç´¢ | æ–‡æœ¬+å¤šæ¨¡æ€å†…å®¹çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æœç´¢ |

---

## 2. æ ¸å¿ƒåŠŸèƒ½

### 2.1 æ–‡æ¡£è§£æé˜¶æ®µ

**æ”¯æŒçš„è§£æå™¨ï¼š**
- **MinerU**: å¼ºå¤§çš„ OCR å’Œè¡¨æ ¼æå–ï¼Œæ”¯æŒ GPU åŠ é€Ÿ
- **Docling**: é’ˆå¯¹ Office æ–‡æ¡£ä¼˜åŒ–ï¼Œæ›´å¥½çš„ç»“æ„ä¿ç•™

**æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ï¼š**
```
PDFã€DOC/DOCXã€PPT/PPTXã€XLS/XLSX
JPG/PNG/BMP/TIFF/GIF/WebP
TXTã€Markdown
```

### 2.2 å¤šæ¨¡æ€å†…å®¹ç†è§£

ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å¤„ç†ï¼š
- ğŸ” **å›¾ç‰‡**: ä½¿ç”¨è§†è§‰æ¨¡å‹ç”Ÿæˆæè¿°
- ğŸ“Š **è¡¨æ ¼**: ç»“æ„åŒ–æ•°æ®è§£é‡Šå’Œç»Ÿè®¡åˆ†æ
- ğŸ“ **å…¬å¼**: LaTeX æ ¼å¼æ”¯æŒï¼Œæ¦‚å¿µæ˜ å°„
- ğŸ”§ **è‡ªå®šä¹‰å†…å®¹**: å¯æ‰©å±•çš„å¤„ç†æ¡†æ¶

### 2.3 çŸ¥è¯†å›¾è°±ç´¢å¼•

- æå–å¤šæ¨¡æ€å®ä½“
- å»ºç«‹è·¨æ¨¡æ€å…³ç³»
- ä¿ç•™æ–‡æ¡£å±‚æ¬¡ç»“æ„
- åŠ æƒå…³ç³»è¯„åˆ†

### 2.4 æ™ºèƒ½æ£€ç´¢

æä¾›ä¸‰ç§æŸ¥è¯¢æ–¹å¼ï¼š
1. **çº¯æ–‡æœ¬æŸ¥è¯¢**: ç›´æ¥æœç´¢çŸ¥è¯†åº“
2. **VLM å¢å¼ºæŸ¥è¯¢**: è‡ªåŠ¨åˆ†ææ£€ç´¢åˆ°çš„å›¾ç‰‡
3. **å¤šæ¨¡æ€æŸ¥è¯¢**: ç»“åˆç‰¹å®šå¤šæ¨¡æ€å†…å®¹è¿›è¡Œåˆ†æ

---

## 3. ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG-Anything ç³»ç»Ÿæ¶æ„                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    æ–‡æ¡£è¾“å…¥ (PDF/Office/Images)
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è§£æå±‚    â”‚  MinerU / Docling
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å†…å®¹åˆ†ç±»  â”‚  è‡ªåŠ¨è·¯ç”±åˆ°ä¸åŒå¤„ç†å™¨
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    å¤šæ¨¡æ€å¤„ç†å™¨ (å¹¶è¡Œå¤„ç†)         â”‚
    â”‚  â€¢ ImageModalProcessor             â”‚
    â”‚  â€¢ TableModalProcessor             â”‚
    â”‚  â€¢ EquationModalProcessor          â”‚
    â”‚  â€¢ GenericModalProcessor           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LightRAG   â”‚  çŸ¥è¯†å›¾è°±æ„å»º
    â”‚ çŸ¥è¯†å›¾è°±   â”‚  â€¢ å®ä½“æå–
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ å…³ç³»å»ºç«‹
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ™ºèƒ½æ£€ç´¢  â”‚  â€¢ å‘é‡ç›¸ä¼¼åº¦
    â”‚            â”‚  â€¢ å›¾éå†
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ ä¸Šä¸‹æ–‡æ„ŸçŸ¥
         â†“
    æŸ¥è¯¢ç»“æœè¾“å‡º
```

---

## 4. å¿«é€Ÿå¼€å§‹

### 4.1 ç¯å¢ƒè¦æ±‚

- **Python**: 3.10+
- **æ“ä½œç³»ç»Ÿ**: Linux/macOS/Windows
- **å¯é€‰**: LibreOffice (å¤„ç† Office æ–‡æ¡£)

### 4.2 å®‰è£…

#### æ–¹å¼ 1: ä» PyPI å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€å®‰è£…
pip install raganything

# å®Œæ•´å®‰è£…ï¼ˆåŒ…å«æ‰€æœ‰å¯é€‰ä¾èµ–ï¼‰
pip install 'raganything[all]'

# æŒ‰éœ€å®‰è£…
pip install 'raganything[image]'        # å›¾ç‰‡æ ¼å¼æ”¯æŒ
pip install 'raganything[text]'         # æ–‡æœ¬æ–‡ä»¶æ”¯æŒ
pip install 'raganything[image,text]'   # å¤šä¸ªåŠŸèƒ½
```

#### æ–¹å¼ 2: ä»æºç å®‰è£…

```bash
# å®‰è£… uv åŒ…ç®¡ç†å™¨
curl -LsSf https://astral.sh/uv/install.sh | sh

# å…‹éš†é¡¹ç›®
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# å®‰è£…ä¾èµ–
uv sync

# å¦‚æœç½‘ç»œè¶…æ—¶ï¼ˆç‰¹åˆ«æ˜¯ opencvï¼‰ï¼š
UV_HTTP_TIMEOUT=120 uv sync

# ä½¿ç”¨ uv è¿è¡Œç¤ºä¾‹
uv run python examples/raganything_example.py --help

# å®‰è£…æ‰€æœ‰å¯é€‰ä¾èµ–
uv sync --all-extras
```

### 4.3 å®‰è£…å¯é€‰ä¾èµ–

#### LibreOffice (Office æ–‡æ¡£æ”¯æŒ)

```bash
# macOS
brew install --cask libreoffice

# Ubuntu/Debian
sudo apt-get install libreoffice

# CentOS/RHEL
sudo yum install libreoffice

# Windows
# ä»å®˜ç½‘ä¸‹è½½: https://www.libreoffice.org/download/download/
```

#### éªŒè¯ MinerU å®‰è£…

```bash
# æ£€æŸ¥ç‰ˆæœ¬
mineru --version

# æ£€æŸ¥é…ç½®
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('âœ… MinerU å®‰è£…æ­£å¸¸' if rag.check_parser_installation() else 'âŒ MinerU å®‰è£…æœ‰é—®é¢˜')"
```

### 4.4 é…ç½® API å¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå‚è€ƒ `env.example`ï¼‰ï¼š

```bash
# OpenAI é…ç½®
LLM_BINDING=openai
LLM_MODEL=gpt-4o-mini
LLM_BINDING_HOST=https://api.openai.com/v1
LLM_BINDING_API_KEY=your_api_key_here

# åµŒå…¥æ¨¡å‹é…ç½®
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIM=3072
EMBEDDING_BINDING_API_KEY=your_api_key_here

# æˆ–ä½¿ç”¨æœ¬åœ° Ollama
# EMBEDDING_BINDING=ollama
# EMBEDDING_MODEL=bge-m3:latest
# EMBEDDING_DIM=1024
# EMBEDDING_BINDING_HOST=http://localhost:11434

# æ–‡æ¡£å¤„ç†é…ç½®
PARSER=mineru                    # æˆ– docling
PARSE_METHOD=auto                # auto/ocr/txt
ENABLE_IMAGE_PROCESSING=true
ENABLE_TABLE_PROCESSING=true
ENABLE_EQUATION_PROCESSING=true
```

---

## 5. ä½¿ç”¨åœºæ™¯å’Œç¤ºä¾‹

### 5.1 åœºæ™¯ä¸€ï¼šå¤„ç†å­¦æœ¯è®ºæ–‡ï¼ˆç«¯åˆ°ç«¯ï¼‰

**ç”¨ä¾‹**: åˆ†æä¸€ç¯‡åŒ…å«å¤§é‡å›¾è¡¨å’Œå…¬å¼çš„ PDF è®ºæ–‡

```python
import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # é…ç½®
    api_key = "your-api-key"
    base_url = "https://api.openai.com/v1"  # å¯é€‰
    
    # åˆ›å»ºé…ç½®
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",
        parse_method="auto",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    
    # LLM å‡½æ•°
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    
    # è§†è§‰æ¨¡å‹å‡½æ•°ï¼ˆç”¨äºå›¾ç‰‡åˆ†æï¼‰
    def vision_model_func(prompt, system_prompt=None, history_messages=[], 
                         image_data=None, messages=None, **kwargs):
        if messages:  # VLM å¢å¼ºæŸ¥è¯¢æ¨¡å¼
            return openai_complete_if_cache(
                "gpt-4o", "", system_prompt=None, history_messages=[],
                messages=messages, api_key=api_key, base_url=base_url, **kwargs
            )
        elif image_data:  # å•å›¾ç‰‡æ¨¡å¼
            return openai_complete_if_cache(
                "gpt-4o", "", system_prompt=None, history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {"role": "user", "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                    ]} if image_data else {"role": "user", "content": prompt}
                ],
                api_key=api_key, base_url=base_url, **kwargs
            )
        else:  # çº¯æ–‡æœ¬
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
    
    # åµŒå…¥å‡½æ•°
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts, model="text-embedding-3-large",
            api_key=api_key, base_url=base_url
        ),
    )
    
    # åˆå§‹åŒ– RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )
    
    # å¤„ç†æ–‡æ¡£
    print("ğŸ“„ æ­£åœ¨å¤„ç†è®ºæ–‡...")
    await rag.process_document_complete(
        file_path="path/to/research_paper.pdf",
        output_dir="./output",
        parse_method="auto"
    )
    print("âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼")
    
    # æŸ¥è¯¢ 1: çº¯æ–‡æœ¬æŸ¥è¯¢
    print("\nğŸ” æ‰§è¡Œæ–‡æœ¬æŸ¥è¯¢...")
    result = await rag.aquery(
        "è®ºæ–‡çš„ä¸»è¦ç ”ç©¶å‘ç°æ˜¯ä»€ä¹ˆï¼Ÿ",
        mode="hybrid"
    )
    print(f"å›ç­”: {result}\n")
    
    # æŸ¥è¯¢ 2: VLM å¢å¼ºæŸ¥è¯¢ï¼ˆè‡ªåŠ¨åˆ†æå›¾ç‰‡ï¼‰
    print("ğŸ” æ‰§è¡Œ VLM å¢å¼ºæŸ¥è¯¢...")
    result = await rag.aquery(
        "å›¾è¡¨ä¸­å±•ç¤ºäº†ä»€ä¹ˆæ•°æ®è¶‹åŠ¿ï¼Ÿ",
        mode="hybrid"
        # vlm_enhanced=True å½“æä¾› vision_model_func æ—¶è‡ªåŠ¨å¯ç”¨
    )
    print(f"å›ç­”: {result}\n")
    
    # æŸ¥è¯¢ 3: å¸¦ç‰¹å®šå…¬å¼çš„å¤šæ¨¡æ€æŸ¥è¯¢
    print("ğŸ” æ‰§è¡Œå¤šæ¨¡æ€æŸ¥è¯¢...")
    result = await rag.aquery_with_multimodal(
        "è§£é‡Šè¿™ä¸ªå…¬å¼å¹¶è¯´æ˜å®ƒä¸è®ºæ–‡çš„å…³è”",
        multimodal_content=[{
            "type": "equation",
            "latex": r"E = mc^2",
            "equation_caption": "è´¨èƒ½æ–¹ç¨‹"
        }],
        mode="hybrid"
    )
    print(f"å›ç­”: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 5.2 åœºæ™¯äºŒï¼šæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£

```python
import asyncio
from raganything import RAGAnything

async def batch_process():
    # ... åˆå§‹åŒ–ä»£ç åŒä¸Š ...
    
    # æ‰¹é‡å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹
    await rag.process_folder_complete(
        folder_path="./documents",
        output_dir="./output",
        file_extensions=[".pdf", ".docx", ".pptx"],
        recursive=True,          # é€’å½’å¤„ç†å­æ–‡ä»¶å¤¹
        max_workers=4            # å¹¶è¡Œå¤„ç†æ•°é‡
    )
    
    print("âœ… æ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæˆï¼")

asyncio.run(batch_process())
```

### 5.3 åœºæ™¯ä¸‰ï¼šç›´æ¥æ’å…¥é¢„è§£æå†…å®¹

**ç”¨ä¾‹**: å·²æœ‰è§£æå¥½çš„å†…å®¹åˆ—è¡¨ï¼Œæ— éœ€é‡æ–°è§£æ

```python
import asyncio
from raganything import RAGAnything

async def insert_parsed_content():
    # ... åˆå§‹åŒ– RAGAnything ...
    
    # é¢„è§£æçš„å†…å®¹åˆ—è¡¨
    content_list = [
        {
            "type": "text",
            "text": "è¿™æ˜¯ç ”ç©¶è®ºæ–‡çš„å¼•è¨€éƒ¨åˆ†ã€‚",
            "page_idx": 0
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„
            "image_caption": ["å›¾1ï¼šç³»ç»Ÿæ¶æ„"],
            "image_footnote": ["æ¥æºï¼šä½œè€…è®¾è®¡"],
            "page_idx": 1
        },
        {
            "type": "table",
            "table_body": "| æ–¹æ³• | å‡†ç¡®ç‡ | F1åˆ†æ•° |\n|-----|-------|-------|\n| æˆ‘ä»¬çš„ | 95.2% | 0.94 |\n| åŸºçº¿ | 87.3% | 0.85 |",
            "table_caption": ["è¡¨1ï¼šæ€§èƒ½å¯¹æ¯”"],
            "table_footnote": ["æµ‹è¯•é›†ç»“æœ"],
            "page_idx": 2
        },
        {
            "type": "equation",
            "latex": r"P(d|q) = \frac{P(q|d) \cdot P(d)}{P(q)}",
            "text": "æ–‡æ¡£ç›¸å…³æ€§æ¦‚ç‡å…¬å¼",
            "page_idx": 3
        }
    ]
    
    # ç›´æ¥æ’å…¥å†…å®¹åˆ—è¡¨
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",
        display_stats=True
    )
    
    # æŸ¥è¯¢
    result = await rag.aquery(
        "ç ”ç©¶çš„ä¸»è¦æ€§èƒ½æŒ‡æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ",
        mode="hybrid"
    )
    print(f"å›ç­”: {result}")

asyncio.run(insert_parsed_content())
```

### 5.4 åœºæ™¯å››ï¼šåŠ è½½å·²æœ‰çš„ LightRAG å®ä¾‹

**ç”¨ä¾‹**: å·²æœ‰ä¸€ä¸ª LightRAG çŸ¥è¯†åº“ï¼Œæƒ³æ·»åŠ å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›

```python
import asyncio
from raganything import RAGAnything
from lightrag import LightRAG
from lightrag.kg.shared_storage import initialize_pipeline_status
import os

async def load_existing():
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²æœ‰å®ä¾‹
    lightrag_dir = "./existing_lightrag_storage"
    if os.path.exists(lightrag_dir) and os.listdir(lightrag_dir):
        print("âœ… æ‰¾åˆ°å·²æœ‰çš„ LightRAG å®ä¾‹")
    
    # åŠ è½½å·²æœ‰çš„ LightRAG å®ä¾‹
    lightrag_instance = LightRAG(
        working_dir=lightrag_dir,
        llm_model_func=...,  # ä½ çš„ LLM å‡½æ•°
        embedding_func=...,  # ä½ çš„åµŒå…¥å‡½æ•°
    )
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()
    
    # ç”¨å·²æœ‰å®ä¾‹åˆå§‹åŒ– RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # ä¼ å…¥å·²æœ‰å®ä¾‹
        vision_model_func=...,       # æ·»åŠ è§†è§‰æ¨¡å‹æ”¯æŒ
    )
    
    # æŸ¥è¯¢å·²æœ‰çŸ¥è¯†åº“
    result = await rag.aquery(
        "è¿™ä¸ªçŸ¥è¯†åº“ä¸­æœ‰ä»€ä¹ˆæ•°æ®ï¼Ÿ",
        mode="hybrid"
    )
    print(f"å›ç­”: {result}")
    
    # å‘å·²æœ‰çŸ¥è¯†åº“æ·»åŠ æ–°çš„å¤šæ¨¡æ€æ–‡æ¡£
    await rag.process_document_complete(
        file_path="new_document.pdf",
        output_dir="./output"
    )

asyncio.run(load_existing())
```

### 5.5 åœºæ™¯äº”ï¼šä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹ï¼ˆæ— éœ€ API å¯†é’¥ï¼‰

```bash
# 1. å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. æ‹‰å–æ¨¡å‹
ollama pull qwen2.5:latest        # LLM æ¨¡å‹
ollama pull bge-m3:latest         # åµŒå…¥æ¨¡å‹
ollama pull llava:latest          # è§†è§‰æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

# 3. å¯åŠ¨ Ollama æœåŠ¡ï¼ˆé»˜è®¤ç«¯å£ 11434ï¼‰
ollama serve
```

```python
import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.ollama import ollama_model_complete, ollama_embed
from lightrag.utils import EmbeddingFunc

async def main():
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",
        enable_image_processing=True,
        enable_table_processing=True,
    )
    
    # ä½¿ç”¨ Ollama
    def llm_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return ollama_model_complete(
            prompt=prompt,
            model="qwen2.5:latest",
            host="http://localhost:11434",
            system_prompt=system_prompt,
            history_messages=history_messages,
            **kwargs
        )
    
    embedding_func = EmbeddingFunc(
        embedding_dim=1024,
        max_token_size=8192,
        func=lambda texts: ollama_embed(
            texts,
            embed_model="bge-m3:latest",
            host="http://localhost:11434"
        ),
    )
    
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_func,
        embedding_func=embedding_func,
    )
    
    # å¤„ç†æ–‡æ¡£
    await rag.process_document_complete(
        file_path="document.pdf",
        output_dir="./output"
    )
    
    # æŸ¥è¯¢
    result = await rag.aquery("æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ", mode="hybrid")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 6. HPC é›†ç¾¤éƒ¨ç½²ï¼ˆSLURMï¼‰

### 6.1 æ¶æ„æ¦‚è§ˆ

åœ¨ HPC é›†ç¾¤ç¯å¢ƒä¸­ï¼ŒRAG-Anything ä½¿ç”¨ä»¥ä¸‹æ¶æ„ï¼š

```
ç™»å½•èŠ‚ç‚¹ (Login Node)
    â”œâ”€â”€ æäº¤ SLURM ä½œä¸š
    â”œâ”€â”€ é…ç½®ç¯å¢ƒå˜é‡
    â””â”€â”€ ç›‘æ§ä½œä¸šçŠ¶æ€

GPU èŠ‚ç‚¹ (GPU Node) - è¿è¡Œ Ollama æœåŠ¡
    â”œâ”€â”€ å¯åŠ¨ Ollama æœåŠ¡ (ollama_gpu_job.sh)
    â”œâ”€â”€ å‘å¸ƒæœåŠ¡ç«¯ç‚¹ä¿¡æ¯
    â””â”€â”€ ä¿æŒæœåŠ¡é•¿æœŸè¿è¡Œ

è®¡ç®—èŠ‚ç‚¹ (Compute Node) - è¿è¡Œ RAG å·¥ä½œè´Ÿè½½
    â”œâ”€â”€ è¯»å– Ollama ç«¯ç‚¹
    â”œâ”€â”€ æ‰§è¡Œæ–‡æ¡£æ‘„å–/æŸ¥è¯¢ (rag_worker_job.sh)
    â””â”€â”€ ä½¿ç”¨å…±äº«å­˜å‚¨
```

### 6.2 ç¯å¢ƒå‡†å¤‡

#### æ­¥éª¤ 1: é…ç½®ç™»å½•èŠ‚ç‚¹ç¯å¢ƒ

```bash
# åœ¨ç™»å½•èŠ‚ç‚¹ä¸Šï¼Œæ¿€æ´»ç¯å¢ƒ
cd /ShareS/UserHome/user007/software/RAG-Anything
source scripts/login_env.sh

# è¾“å‡ºç¤ºä¾‹ï¼š
# [INFO] RAG-Anything login environment configured.
# [INFO] Shared root: /ShareS/UserHome/user007/rag-data
# [INFO] Runtime state: /ShareS/UserHome/user007/rag-data/runtime
# [INFO] Logs: /ShareS/UserHome/user007/software/RAG-Anything/logs/slurm
```

è¿™ä¸ªè„šæœ¬ä¼šè®¾ç½®ï¼š
- `RAG_SHARED_ROOT`: å…±äº«æ•°æ®ç›®å½•
- `RAG_RUNTIME_STATE`: è¿è¡Œæ—¶çŠ¶æ€æ–‡ä»¶ï¼ˆOllama ç«¯ç‚¹ä¿¡æ¯ï¼‰
- `LOG_ROOT`: æ—¥å¿—ç›®å½•
- `OLLAMA_*`: Ollama é…ç½®
- `RERANKER_*`: é‡æ’åºæ¨¡å‹é…ç½®

#### æ­¥éª¤ 2: å‡†å¤‡å¿…éœ€çš„æ–‡ä»¶å’Œæ¨¡å‹

```bash
# ç¡®ä¿å…±äº«ç›®å½•å­˜åœ¨
mkdir -p ${RAG_SHARED_ROOT}
mkdir -p ${RAG_RUNTIME_STATE}
mkdir -p ${LOG_ROOT}

# ä¸‹è½½ Reranker æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
# è¿™ä¸ªæ¨¡å‹ä¼šè¢« GPU èŠ‚ç‚¹å’Œè®¡ç®—èŠ‚ç‚¹å…±äº«
mkdir -p ${HOME}/.huggingface/models
# ä¸‹è½½ bge-v2-gemma æˆ–å…¶ä»–é‡æ’åºæ¨¡å‹åˆ°æ­¤ç›®å½•

# æ£€æŸ¥ Ollama å®‰è£…è„šæœ¬
ls -l ${HOME}/setup/ollama.sh
```

### 6.3 å¯åŠ¨ Ollama GPU æœåŠ¡

#### æ–¹æ³• 1: ä½¿ç”¨é»˜è®¤é…ç½®

```bash
# æäº¤ GPU ä½œä¸šï¼ˆä½¿ç”¨è„šæœ¬ä¸­çš„é»˜è®¤é…ç½®ï¼‰
sbatch scripts/slurm/ollama_gpu_job.sh

# æ£€æŸ¥ä½œä¸šçŠ¶æ€
squeue -u $USER

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/slurm/ollama-<JOB_ID>.out
```

#### æ–¹æ³• 2: è‡ªå®šä¹‰èµ„æºé…ç½®

```bash
# ä½¿ç”¨ä¸åŒçš„åˆ†åŒºå’Œ GPU æ•°é‡
sbatch --partition=A100 --gres=gpu:2 scripts/slurm/ollama_gpu_job.sh

# è‡ªå®šä¹‰è¿è¡Œæ—¶é—´
sbatch --time=48:00:00 scripts/slurm/ollama_gpu_job.sh
```

#### æ–¹æ³• 3: è¦†ç›–ç¯å¢ƒå˜é‡

```bash
# è‡ªå®šä¹‰ Ollama é…ç½®
export OLLAMA_PORT=12345
export OLLAMA_CACHE=${HOME}/custom_ollama_cache
sbatch scripts/slurm/ollama_gpu_job.sh
```

#### éªŒè¯ Ollama æœåŠ¡

```bash
# ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆé€šå¸¸ 30-60 ç§’ï¼‰
sleep 60

# æ£€æŸ¥æœåŠ¡ç«¯ç‚¹æ–‡ä»¶
cat ${RAG_RUNTIME_STATE}/ollama_service.json

# è¾“å‡ºç¤ºä¾‹ï¼š
# {
#   "host": "gpu-node-01",
#   "port": 11434,
#   "job_id": "123456",
#   "cache": "/home/user007/.ollama/models",
#   "updated_at": "2025-01-15T10:30:00Z"
# }

# æµ‹è¯•è¿æ¥ï¼ˆä»ç™»å½•èŠ‚ç‚¹ï¼‰
curl http://gpu-node-01:11434/api/tags
```

### 6.4 è¿è¡Œ RAG å·¥ä½œè´Ÿè½½

#### åœºæ™¯ 1: æ–‡æ¡£æ‘„å–ï¼ˆIngestï¼‰

```bash
# è®¾ç½®è¾“å…¥æ–‡ä»¶
export RAG_INPUT_FILE=/ShareS/UserHome/user007/data/paper.pdf
export RAG_WORKER_MODE=ingest

# æäº¤ä½œä¸šï¼ˆä½¿ç”¨é»˜è®¤å‘½ä»¤ï¼‰
sbatch scripts/slurm/rag_worker_job.sh

# æˆ–æŒ‡å®š Ollama ä¸»æœºï¼ˆå¦‚æœæœªè‡ªåŠ¨å‘ç°ï¼‰
export OLLAMA_HOST=http://gpu-node-01:11434
sbatch scripts/slurm/rag_worker_job.sh
```

#### åœºæ™¯ 2: è‡ªå®šä¹‰å‘½ä»¤

```bash
# è¿è¡Œè‡ªå®šä¹‰ Python è„šæœ¬
sbatch scripts/slurm/rag_worker_job.sh -- \
  uv run python scripts/cluster_rag_worker.py \
  --mode ingest \
  --input-file /path/to/document.pdf \
  --working-dir ${RAG_SHARED_ROOT}/workspace \
  --parser mineru \
  --llm-model qwen2.5:latest \
  --embed-model bge-m3:latest \
  --embed-dim 1024
```

#### åœºæ™¯ 3: æŸ¥è¯¢çŸ¥è¯†åº“

```bash
# æäº¤æŸ¥è¯¢ä½œä¸š
sbatch scripts/slurm/rag_worker_job.sh -- \
  uv run python scripts/cluster_rag_worker.py \
  --mode query \
  --query "è®ºæ–‡çš„ä¸»è¦å‘ç°æ˜¯ä»€ä¹ˆï¼Ÿ" \
  --working-dir ${RAG_SHARED_ROOT}/workspace \
  --query-mode hybrid
```

### 6.5 ç›‘æ§å’Œè°ƒè¯•

#### æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹ Ollama æ—¥å¿—
tail -f logs/slurm/ollama-<JOB_ID>.out
tail -f logs/slurm/ollama-serve.log

# å®æ—¶æŸ¥çœ‹ RAG worker æ—¥å¿—
tail -f logs/slurm/rag-worker-<JOB_ID>.out

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
ls -lht logs/slurm/
```

#### å¸¸è§é—®é¢˜æ’æŸ¥

**é—®é¢˜ 1: RAG worker æ‰¾ä¸åˆ° Ollama æœåŠ¡**

```bash
# æ£€æŸ¥æœåŠ¡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -l ${RAG_RUNTIME_STATE}/ollama_service.json

# æ‰‹åŠ¨è®¾ç½® OLLAMA_HOST
export OLLAMA_HOST=http://gpu-node-01:11434
```

**é—®é¢˜ 2: GPU èŠ‚ç‚¹æ— æ³•å¯åŠ¨ Ollama**

```bash
# æ£€æŸ¥ Ollama å®‰è£…
which ollama
ollama --version

# æ£€æŸ¥ GPU å¯ç”¨æ€§
nvidia-smi

# æ£€æŸ¥ç¯å¢ƒè„šæœ¬
cat ${HOME}/setup/ollama.sh
```

**é—®é¢˜ 3: è®¡ç®—èŠ‚ç‚¹æ²¡æœ‰ç½‘ç»œè®¿é—®**

```bash
# ç¡®ä¿ tiktoken ç¼“å­˜å·²é¢„ä¸‹è½½
export TIKTOKEN_CACHE_DIR=${HOME}/.cache/tiktoken
ls -l ${TIKTOKEN_CACHE_DIR}

# é¢„ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°å…±äº«å­˜å‚¨
# åœ¨æœ‰ç½‘ç»œçš„ç™»å½•èŠ‚ç‚¹æ‰§è¡Œï¼š
ollama pull qwen2.5:latest
ollama pull bge-m3:latest
```

### 6.6 é›†ç¾¤é…ç½®æ–‡ä»¶å‚è€ƒ

#### `scripts/login_env.sh` - å…³é”®ç¯å¢ƒå˜é‡

```bash
# å…±äº«å­˜å‚¨
RAG_SHARED_ROOT=/ShareS/UserHome/user007/rag-data
RAG_RUNTIME_STATE=${RAG_SHARED_ROOT}/runtime

# Ollama é…ç½®
OLLAMA_PORT=11434
OLLAMA_GENERATE_MODEL=qwen3:235b
OLLAMA_EMBED_MODEL=qwen3-embedding:8b
OLLAMA_EMBED_DIM=8192
OLLAMA_TIMEOUT_SECONDS=300

# Reranker é…ç½®
RERANKER_MODEL_PATH=${HOME}/.huggingface/models/bge-v2-gemma
RERANKER_USE_FP16=1

# ç¼“å­˜ç›®å½•
HF_HOME=${HOME}/.huggingface
TIKTOKEN_CACHE_DIR=${HOME}/.cache/tiktoken
```

#### è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹

```bash
# åœ¨æäº¤ä½œä¸šå‰è¦†ç›–é»˜è®¤å€¼
export OLLAMA_GENERATE_MODEL=llama3:70b
export OLLAMA_EMBED_MODEL=nomic-embed-text:latest
export OLLAMA_EMBED_DIM=768
export OLLAMA_TIMEOUT_SECONDS=600

# æäº¤ä½œä¸š
sbatch scripts/slurm/rag_worker_job.sh
```

### 6.7 æœ€ä½³å®è·µ

1. **ä½¿ç”¨å…±äº«å­˜å‚¨**: ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹è®¿é—®ç›¸åŒçš„ `RAG_SHARED_ROOT`
2. **é¢„ä¸‹è½½æ¨¡å‹**: åœ¨ç™»å½•èŠ‚ç‚¹é¢„å…ˆä¸‹è½½æ‰€æœ‰æ¨¡å‹åˆ°å…±äº«ç¼“å­˜
3. **ç›‘æ§èµ„æº**: ä½¿ç”¨ `squeue`, `sacct` ç›‘æ§ä½œä¸šçŠ¶æ€
4. **æ—¥å¿—ç®¡ç†**: å®šæœŸæ¸…ç† `logs/slurm/` ç›®å½•
5. **é•¿æœŸæœåŠ¡**: Ollama GPU ä½œä¸šè®¾ç½®è¾ƒé•¿çš„æ—¶é—´é™åˆ¶ï¼ˆ24-48å°æ—¶ï¼‰
6. **é”™è¯¯å¤„ç†**: è„šæœ¬åŒ…å«å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨æ¸…ç†é€»è¾‘

---

## 7. é…ç½®è¯¦è§£

### 7.1 è§£æå™¨é…ç½®

#### MinerU é…ç½®

```python
# åŸºç¡€è§£æ
await rag.process_document_complete(
    file_path="document.pdf",
    parser="mineru",
    parse_method="auto",  # auto/ocr/txt
)

# é«˜çº§é…ç½®
await rag.process_document_complete(
    file_path="document.pdf",
    parser="mineru",
    parse_method="auto",
    
    # MinerU ç‰¹å®šå‚æ•°
    lang="ch",              # OCR è¯­è¨€: ch/en/ja
    device="cuda:0",        # æ¨ç†è®¾å¤‡: cpu/cuda/npu/mps
    start_page=0,           # èµ·å§‹é¡µç ï¼ˆPDFï¼‰
    end_page=10,            # ç»“æŸé¡µç 
    formula=True,           # å¯ç”¨å…¬å¼è§£æ
    table=True,             # å¯ç”¨è¡¨æ ¼è§£æ
    backend="pipeline",     # åç«¯: pipeline/vlm-*
    source="huggingface",   # æ¨¡å‹æ¥æº
)
```

#### Docling é…ç½®

```python
await rag.process_document_complete(
    file_path="document.docx",
    parser="docling",
    parse_method="auto",
)
```

### 7.2 å¤„ç†å™¨é…ç½®

```python
config = RAGAnythingConfig(
    working_dir="./rag_storage",
    parser="mineru",
    parse_method="auto",
    
    # å¤šæ¨¡æ€å¤„ç†å¼€å…³
    enable_image_processing=True,
    enable_table_processing=True,
    enable_equation_processing=True,
)
```

### 7.3 æŸ¥è¯¢æ¨¡å¼

```python
# å››ç§æŸ¥è¯¢æ¨¡å¼
result = await rag.aquery("é—®é¢˜", mode="naive")    # ç®€å•å‘é‡æœç´¢
result = await rag.aquery("é—®é¢˜", mode="local")    # å±€éƒ¨å›¾éå†
result = await rag.aquery("é—®é¢˜", mode="global")   # å…¨å±€å›¾åˆ†æ
result = await rag.aquery("é—®é¢˜", mode="hybrid")   # æ··åˆæ¨¡å¼ï¼ˆæ¨èï¼‰
```

### 7.4 ç¯å¢ƒå˜é‡é…ç½®

`.env` æ–‡ä»¶å®Œæ•´ç¤ºä¾‹ï¼š

```bash
# ===== åŸºç¡€é…ç½® =====
# LLM é…ç½®
LLM_BINDING=openai
LLM_MODEL=gpt-4o-mini
LLM_BINDING_HOST=https://api.openai.com/v1
LLM_BINDING_API_KEY=your_api_key

# åµŒå…¥æ¨¡å‹é…ç½®
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIM=3072
EMBEDDING_BINDING_API_KEY=your_api_key

# ===== RAGAnything é…ç½® =====
# è§£æå™¨
PARSER=mineru
PARSE_METHOD=auto
OUTPUT_DIR=./output

# å¤šæ¨¡æ€å¤„ç†
ENABLE_IMAGE_PROCESSING=true
ENABLE_TABLE_PROCESSING=true
ENABLE_EQUATION_PROCESSING=true

# æ‰¹é‡å¤„ç†
MAX_CONCURRENT_FILES=2
RECURSIVE_FOLDER_PROCESSING=true

# ===== é«˜çº§é…ç½® =====
# æ£€ç´¢å‚æ•°
TOP_K=60
COSINE_THRESHOLD=0.2
MAX_TOKEN_TEXT_CHUNK=4000

# å®ä½“å’Œå…³ç³»é…ç½®
SUMMARY_LANGUAGE=Chinese
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100

# LLM ç¼“å­˜
ENABLE_LLM_CACHE=true
MAX_ASYNC=4
MAX_TOKENS=32768
TEMPERATURE=0

# ===== é›†ç¾¤é…ç½®ï¼ˆå¯é€‰ï¼‰=====
# Ollama é…ç½®
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_GENERATE_MODEL=qwen2.5:latest
OLLAMA_EMBED_MODEL=bge-m3:latest
OLLAMA_EMBED_DIM=1024

# å…±äº«å­˜å‚¨
RAG_SHARED_ROOT=/path/to/shared/storage
RERANKER_MODEL_PATH=/path/to/reranker/model
```

---

## 8. å¸¸è§é—®é¢˜

### 8.1 å®‰è£…ç›¸å…³

**Q: MinerU å®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version  # éœ€è¦ 3.10+

# æ¸…ç†ç¼“å­˜é‡æ–°å®‰è£…
pip cache purge
pip install --no-cache-dir 'raganything[all]'

# å¦‚æœç½‘ç»œè¶…æ—¶
pip install --default-timeout=100 raganything
```

**Q: LibreOffice æœªæ£€æµ‹åˆ°ï¼Ÿ**

```bash
# æ£€æŸ¥å®‰è£…
which libreoffice
libreoffice --version

# æµ‹è¯• Office æ–‡æ¡£è§£æ
python examples/office_document_test.py --check-libreoffice --file dummy
```

**Q: GPU ç›¸å…³é—®é¢˜ï¼Ÿ**

```bash
# æ£€æŸ¥ CUDA
nvidia-smi
nvcc --version

# MinerU GPU åŠ é€Ÿ
await rag.process_document_complete(
    file_path="doc.pdf",
    device="cuda:0",  # æŒ‡å®š GPU
    backend="pipeline"
)
```

### 8.2 ä½¿ç”¨ç›¸å…³

**Q: å¦‚ä½•å¤„ç†å¤§æ–‡ä»¶ï¼Ÿ**

```python
# æ–¹æ³• 1: åˆ†é¡µå¤„ç†
await rag.process_document_complete(
    file_path="large.pdf",
    start_page=0,
    end_page=50  # å…ˆå¤„ç†å‰ 50 é¡µ
)

# æ–¹æ³• 2: å¢åŠ è¶…æ—¶
import os
os.environ['TIMEOUT'] = '600'  # 10 åˆ†é’Ÿ

# æ–¹æ³• 3: è°ƒæ•´ chunk å¤§å°
config = RAGAnythingConfig(
    chunk_size=800,  # å‡å° chunk å¤§å°
    chunk_overlap=50
)
```

**Q: å¦‚ä½•æé«˜æŸ¥è¯¢é€Ÿåº¦ï¼Ÿ**

```python
# 1. ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹
EMBEDDING_BINDING=ollama
EMBEDDING_MODEL=bge-m3:latest

# 2. è°ƒæ•´æ£€ç´¢å‚æ•°
os.environ['TOP_K'] = '30'  # å‡å°‘è¿”å›æ•°é‡
os.environ['MAX_ASYNC'] = '8'  # å¢åŠ å¹¶å‘

# 3. ä½¿ç”¨ç¼“å­˜
ENABLE_LLM_CACHE=true
```

**Q: å¦‚ä½•å¤„ç†ç‰¹å®šè¯­è¨€æ–‡æ¡£ï¼Ÿ**

```python
# OCR è¯­è¨€è®¾ç½®
await rag.process_document_complete(
    file_path="chinese_doc.pdf",
    lang="ch",  # ä¸­æ–‡
    parse_method="ocr"
)

# å®ä½“æå–è¯­è¨€
os.environ['SUMMARY_LANGUAGE'] = 'Chinese'
```

### 8.3 é”™è¯¯å¤„ç†

**é”™è¯¯ 1: `ModuleNotFoundError: No module named 'raganything'`**

```bash
# ç¡®è®¤å®‰è£…
pip list | grep raganything

# é‡æ–°å®‰è£…
pip install --upgrade raganything
```

**é”™è¯¯ 2: `FileNotFoundError: [Errno 2] No such file or directory: 'mineru'`**

```bash
# æ£€æŸ¥ MinerU
which mineru
mineru --version

# é‡æ–°å®‰è£…
pip install --force-reinstall 'mineru[core]'
```

**é”™è¯¯ 3: `RuntimeError: CUDA out of memory`**

```python
# ä½¿ç”¨ CPU
await rag.process_document_complete(
    file_path="doc.pdf",
    device="cpu"
)

# æˆ–å‡å°æ‰¹å¤„ç†å¤§å°
os.environ['EMBEDDING_BATCH_NUM'] = '16'
```

---

## 9. è¿›é˜¶ä½¿ç”¨

### 9.1 è‡ªå®šä¹‰æ¨¡æ€å¤„ç†å™¨

```python
from raganything.modalprocessors import GenericModalProcessor

class CustomVideoProcessor(GenericModalProcessor):
    """è‡ªå®šä¹‰è§†é¢‘å¤„ç†å™¨"""
    
    async def process_multimodal_content(
        self, 
        modal_content, 
        content_type, 
        file_path, 
        entity_name
    ):
        # æå–è§†é¢‘å…³é”®å¸§
        frames = self.extract_key_frames(modal_content['video_path'])
        
        # ä½¿ç”¨ VLM åˆ†æå¸§
        descriptions = []
        for frame in frames:
            desc = await self.modal_caption_func(
                prompt="æè¿°è¿™ä¸€å¸§çš„å†…å®¹",
                image_data=frame
            )
            descriptions.append(desc)
        
        # åˆå¹¶æè¿°
        enhanced_description = "\n".join(descriptions)
        
        # åˆ›å»ºå®ä½“
        entity_info = self.create_custom_entity(
            enhanced_description, 
            entity_name
        )
        
        return await self._create_entity_and_chunk(
            enhanced_description, 
            entity_info, 
            file_path
        )

# ä½¿ç”¨è‡ªå®šä¹‰å¤„ç†å™¨
video_processor = CustomVideoProcessor(
    lightrag=rag.lightrag,
    modal_caption_func=vision_model_func
)

# å¤„ç†è§†é¢‘å†…å®¹
await video_processor.process_multimodal_content(
    modal_content={"video_path": "video.mp4"},
    content_type="video",
    file_path="presentation.pptx",
    entity_name="Demo Video"
)
```

### 9.2 ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤„ç†

```python
# å¯ç”¨ä¸Šä¸‹æ–‡æå–
os.environ['CONTEXT_WINDOW'] = '2'  # å‰å 2 ä¸ªå…ƒç´ 
os.environ['CONTEXT_MODE'] = 'page'  # æˆ– 'element'
os.environ['INCLUDE_HEADERS'] = 'true'
os.environ['INCLUDE_CAPTIONS'] = 'true'

# å¤„ç†æ–‡æ¡£ï¼ˆè‡ªåŠ¨æå–ä¸Šä¸‹æ–‡ï¼‰
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output"
)
```

è¯¦ç»†æ–‡æ¡£: [context_aware_processing.md](context_aware_processing.md)

### 9.3 æ‰¹å¤„ç†ä¼˜åŒ–

```python
# å¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡ä»¶
os.environ['MAX_CONCURRENT_FILES'] = '4'
os.environ['MAX_PARALLEL_INSERT'] = '2'

await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    max_workers=4
)
```

è¯¦ç»†æ–‡æ¡£: [batch_processing.md](batch_processing.md)

### 9.4 å¢å¼º Markdown è¾“å‡º

```python
# å¯ç”¨å¢å¼ºè¾“å‡º
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output",
    enhanced_markdown=True  # ç”Ÿæˆå¢å¼ºçš„ Markdown
)
```

è¯¦ç»†æ–‡æ¡£: [enhanced_markdown.md](enhanced_markdown.md)

### 9.5 æ•°æ®åº“åç«¯é€‰æ‹©

```bash
# PostgreSQL + pgvectorï¼ˆæ¨èï¼‰
LIGHTRAG_KV_STORAGE=PGKVStorage
LIGHTRAG_VECTOR_STORAGE=PGVectorStorage
LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Neo4j å›¾æ•°æ®åº“
NEO4J_URI=neo4j+s://xxx.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password

# Milvus å‘é‡æ•°æ®åº“
MILVUS_URI=http://localhost:19530
MILVUS_DB_NAME=lightrag
```

---

## 10. æ€»ç»“å’Œä¸‹ä¸€æ­¥

### 10.1 å­¦ä¹ è·¯å¾„å»ºè®®

```
ç¬¬ 1 å¤©ï¼šåŸºç¡€è®¾ç½®
â”œâ”€â”€ å®‰è£… RAG-Anything
â”œâ”€â”€ é…ç½® API å¯†é’¥æˆ– Ollama
â””â”€â”€ è¿è¡Œç¬¬ä¸€ä¸ªç¤ºä¾‹

ç¬¬ 2 å¤©ï¼šç†è§£æ ¸å¿ƒæ¦‚å¿µ
â”œâ”€â”€ æ–‡æ¡£è§£ææµç¨‹
â”œâ”€â”€ å¤šæ¨¡æ€å¤„ç†å™¨
â””â”€â”€ æŸ¥è¯¢æ¨¡å¼å¯¹æ¯”

ç¬¬ 3 å¤©ï¼šå®è·µåœºæ™¯
â”œâ”€â”€ å¤„ç†è‡ªå·±çš„æ–‡æ¡£
â”œâ”€â”€ å°è¯•ä¸åŒæŸ¥è¯¢æ–¹å¼
â””â”€â”€ è°ƒæ•´é…ç½®å‚æ•°

ç¬¬ 4 å¤©ï¼šè¿›é˜¶åŠŸèƒ½
â”œâ”€â”€ æ‰¹å¤„ç†æ–‡æ¡£
â”œâ”€â”€ è‡ªå®šä¹‰å¤„ç†å™¨
â””â”€â”€ é›†æˆåˆ°å·¥ä½œæµ

ç¬¬ 5 å¤©ï¼šç”Ÿäº§éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ HPC é›†ç¾¤éƒ¨ç½²
â”œâ”€â”€ æ•°æ®åº“åç«¯é…ç½®
â””â”€â”€ æ€§èƒ½ä¼˜åŒ–
```

### 10.2 å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# å®‰è£…
pip install 'raganything[all]'

# è¿è¡Œç¤ºä¾‹
python examples/raganything_example.py document.pdf --api-key YOUR_KEY

# æ£€æŸ¥å®‰è£…
python -c "from raganything import RAGAnything; print('âœ… OK')"

# æµ‹è¯• MinerU
mineru --version

# æµ‹è¯• LibreOffice
libreoffice --version

# HPC: å¯åŠ¨ Ollama
source scripts/login_env.sh
sbatch scripts/slurm/ollama_gpu_job.sh

# HPC: æäº¤ RAG ä½œä¸š
export RAG_INPUT_FILE=/path/to/doc.pdf
sbatch scripts/slurm/rag_worker_job.sh
```

### 10.3 å‚è€ƒèµ„æº

- **ä¸»æ–‡æ¡£**: [README.md](../README.md)
- **ç¤ºä¾‹ä»£ç **: `examples/` ç›®å½•
- **é…ç½®å‚è€ƒ**: `env.example`
- **GitHub Issues**: [æŠ¥å‘Šé—®é¢˜](https://github.com/HKUDS/RAG-Anything/issues)
- **è®ºæ–‡**: [LightRAG arXiv](https://arxiv.org/abs/2410.05779)

### 10.4 ç¤¾åŒºæ”¯æŒ

- **Discord**: [åŠ å…¥ç¤¾åŒº](https://discord.gg/yF2MmDJyGJ)
- **å¾®ä¿¡ç¾¤**: è§ [Issue #7](https://github.com/HKUDS/RAG-Anything/issues/7)
- **GitHub Discussions**: [è®¨è®ºåŒº](https://github.com/HKUDS/RAG-Anything/discussions)

---

## é™„å½•: æœ¯è¯­è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è¯´æ˜ |
|-----|------|------|
| æ£€ç´¢å¢å¼ºç”Ÿæˆ | RAG (Retrieval-Augmented Generation) | ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„ AI æŠ€æœ¯ |
| å¤šæ¨¡æ€ | Multimodal | å¤„ç†æ–‡æœ¬ã€å›¾åƒã€è¡¨æ ¼ç­‰å¤šç§ç±»å‹çš„æ•°æ® |
| çŸ¥è¯†å›¾è°± | Knowledge Graph | ç»“æ„åŒ–çš„å®ä½“å’Œå…³ç³»ç½‘ç»œ |
| åµŒå…¥ | Embedding | å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º |
| å¤§è¯­è¨€æ¨¡å‹ | LLM (Large Language Model) | å¦‚ GPTã€Qwen ç­‰ |
| è§†è§‰è¯­è¨€æ¨¡å‹ | VLM (Vision Language Model) | å¯å¤„ç†å›¾åƒçš„ LLM |
| æ–‡æ¡£è§£æ | Document Parsing | ä» PDF ç­‰æ ¼å¼æå–ç»“æ„åŒ–å†…å®¹ |
| OCR | Optical Character Recognition | å…‰å­¦å­—ç¬¦è¯†åˆ« |
| å‘é‡æ•°æ®åº“ | Vector Database | å­˜å‚¨å’Œæ£€ç´¢å‘é‡åµŒå…¥çš„æ•°æ®åº“ |
| æ··åˆæ£€ç´¢ | Hybrid Retrieval | ç»“åˆå‘é‡æœç´¢å’Œå›¾éå† |

---

## ç»“è¯­

è¿™ä»½æŒ‡å—æ¶µç›–äº† RAG-Anything ä»å…¥é—¨åˆ°è¿›é˜¶çš„å„ä¸ªæ–¹é¢ã€‚æ— è®ºä½ æ˜¯ç ”ç©¶äººå‘˜ã€å¼€å‘è€…è¿˜æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œéƒ½å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„ä½¿ç”¨æ–¹å¼ã€‚

**å…³é”®è¦ç‚¹å›é¡¾ï¼š**

1. âœ… **ç®€å•å¼€å§‹**: PyPI å®‰è£… + OpenAI API
2. âœ… **æœ¬åœ°éƒ¨ç½²**: Ollama + å…è´¹æ¨¡å‹
3. âœ… **ç”Ÿäº§çº§**: HPC é›†ç¾¤ + SLURM
4. âœ… **çµæ´»æ‰©å±•**: è‡ªå®šä¹‰å¤„ç†å™¨ + å¤šç§åç«¯

å¼€å§‹ä½ çš„ RAG-Anything ä¹‹æ—…å§ï¼ ğŸš€

---

<div align="center">

**[â­ Star é¡¹ç›®](https://github.com/HKUDS/RAG-Anything)** | 
**[ğŸ› æŠ¥å‘Šé—®é¢˜](https://github.com/HKUDS/RAG-Anything/issues)** | 
**[ğŸ’¬ è®¨è®ºäº¤æµ](https://github.com/HKUDS/RAG-Anything/discussions)**

</div>

